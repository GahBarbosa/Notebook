## ğŸ” **1. SeleÃ§Ã£o Univariada (Ex: SelectKBest)**

Seleciona as melhores variÃ¡veis baseado em testes estatÃ­sticos independentes, como ANOVA, chi-quadrado ou correlaÃ§Ã£o.

|âœ… **PrÃ³s**|âŒ **Contras**|
|---|---|
|Simples e rÃ¡pida de aplicar|Avalia cada variÃ¡vel **isoladamente** (ignora interaÃ§Ãµes)|
|Ajuda a eliminar variÃ¡veis irrelevantes cedo|Pode descartar variÃ¡veis que, combinadas, sÃ£o importantes|
|Boa para datasets muito grandes|LimitaÃ§Ã£o em casos de nÃ£o-linearidade|

---

## ğŸ” **2. Recursive Feature Elimination (RFE)**

Treina o modelo vÃ¡rias vezes removendo as menos importantes a cada rodada.

|âœ… **PrÃ³s**|âŒ **Contras**|
|---|---|
|Considera **interaÃ§Ã£o entre variÃ¡veis**|Computacionalmente **pesado** em datasets grandes|
|Oferece um ranking de importÃ¢ncia|Pode superestimar variÃ¡veis que o modelo escolhido favorece|
|Funciona bem com modelos lineares e nÃ£o lineares|SensÃ­vel ao **overfitting** se nÃ£o usado com validaÃ§Ã£o cruzada|

---

## ğŸ” **3. Feature Importance (Ex: Random Forest, XGBoost)**

Usa algoritmos de Ã¡rvore para calcular a importÃ¢ncia de cada variÃ¡vel durante o treinamento.

|âœ… **PrÃ³s**|âŒ **Contras**|
|---|---|
|Considera relaÃ§Ãµes nÃ£o-lineares e interaÃ§Ãµes|ImportÃ¢ncia pode ser **enviesada** por variÃ¡veis categÃ³ricas com muitos nÃ­veis|
|Boa performance com grandes conjuntos de dados|DifÃ­cil interpretar a influÃªncia real de cada variÃ¡vel|
|Funciona direto com o modelo|Nem sempre a importÃ¢ncia reflete impacto direto no target|

---

## ğŸ” **4. Lasso (RegularizaÃ§Ã£o L1)**

Modelo de regressÃ£o linear com penalizaÃ§Ã£o que forÃ§a coeficientes de variÃ¡veis menos relevantes a zero.

|âœ… **PrÃ³s**|âŒ **Contras**|
|---|---|
|Faz **seleÃ§Ã£o automÃ¡tica** de variÃ¡veis|Funciona sÃ³ com **modelos lineares**|
|Reduz overfitting|Pode eliminar variÃ¡veis que, combinadas, sÃ£o relevantes|
|Simples de implementar|SensÃ­vel a escala dos dados (requer normalizaÃ§Ã£o)|

---

## ğŸ” **Resumo: Qual usar e quando?**

|CenÃ¡rio|Melhor OpÃ§Ã£o|
|---|---|
|Dataset pequeno e linear|Lasso ou RFE|
|Dataset grande com muitas variÃ¡veis irrelevantes|SelectKBest ou Feature Importance|
|Muitos dados e busca de interaÃ§Ãµes|Random Forest / XGBoost (Feature Importance)|
|Alta performance sem preocupaÃ§Ã£o com explicaÃ§Ã£o|Tree-based models ou RFE|

---

Se quiser, posso montar um fluxo ou te indicar a melhor tÃ©cnica pro seu caso. Qual o tamanho do seu dataset e vocÃª pretende focar em modelos lineares ou de Ã¡rvore?